{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangweihao/.conda/envs/jwhenvtc/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set gpu: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from data.datamgr import SimpleDataManager , SetDataManager\n",
    "from models.predesigned_modules import resnet12\n",
    "import sys\n",
    "import os\n",
    "from utils import *\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# fix seed\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "import tqdm\n",
    "from torch.nn.parallel import DataParallel\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "from models.models_mae import mae_vit_base_patch16\n",
    "# from sklearn import svm     #导入算法模块\n",
    "\n",
    "#--------------参数设置--------------------\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--image_size', default=224, type=int, choices=[84, 224], help='input image size, 84 for miniImagenet and tieredImagenet, 224 for cub')\n",
    "parser.add_argument('--dataset', default='mini_imagenet', choices=['mini_imagenet','tiered_imagenet','cub'])\n",
    "parser.add_argument('--data_path', default='/home/jiangweihao/data/mini-imagenet/',type=str, help='dataset path')\n",
    "\n",
    "parser.add_argument('--train_n_episode', default=300, type=int, help='number of episodes in meta train')\n",
    "parser.add_argument('--val_n_episode', default=300, type=int, help='number of episodes in meta val')\n",
    "parser.add_argument('--train_n_way', default=5, type=int, help='number of classes used for meta train')\n",
    "parser.add_argument('--val_n_way', default=5, type=int, help='number of classes used for meta val')\n",
    "parser.add_argument('--n_shot', default=1, type=int, help='number of labeled data in each class, same as n_support')\n",
    "parser.add_argument('--n_query', default=15, type=int, help='number of unlabeled data in each class')\n",
    "parser.add_argument('--num_classes', default=64, type=int, help='total number of classes in pretrain')\n",
    "\n",
    "parser.add_argument('--batch_size', default=128, type=int, help='total number of batch_size in pretrain')\n",
    "# parser.add_argument('--freq', default=10, type=int, help='total number of inner frequency')\n",
    "\n",
    "parser.add_argument('--momentum', default=0.9, type=int, help='parameter of optimization')\n",
    "parser.add_argument('--weight_decay', default=5.e-4, type=int, help='parameter of optimization')\n",
    "\n",
    "parser.add_argument('--gpu', default='3')\n",
    "parser.add_argument('--epochs', default=100)\n",
    "\n",
    "params = parser.parse_args(args=['--gpu', '4',  '--epochs','1'])\n",
    "\n",
    "# -------------设置GPU--------------------\n",
    "set_gpu(params.gpu)\n",
    "# -------------导入数据--------------------\n",
    "\n",
    "json_file_read = False\n",
    "if params.dataset == 'mini_imagenet':\n",
    "        base_file = 'train'\n",
    "        val_file = 'val'\n",
    "        params.num_classes = 64\n",
    "elif params.dataset == 'cub':\n",
    "    base_file = 'base.json'\n",
    "    val_file = 'val.json'\n",
    "    json_file_read = True\n",
    "    params.num_classes = 200\n",
    "elif params.dataset == 'tiered_imagenet':\n",
    "    base_file = 'train'\n",
    "    val_file = 'val'\n",
    "    params.num_classes = 351\n",
    "else:\n",
    "    ValueError('dataset error')\n",
    "\n",
    "# -----------  base data ----------------------\n",
    "base_datamgr = SimpleDataManager(params.data_path, params.image_size, batch_size=params.batch_size, json_read=json_file_read)\n",
    "base_loader = base_datamgr.get_data_loader(base_file, aug=True)\n",
    "\n",
    "#-----------  train data ----------------------\n",
    "train_few_shot_params = dict(n_way=params.train_n_way, n_support=params.n_shot)\n",
    "train_datamgr = SetDataManager(params.data_path, params.image_size, n_query=params.n_query, n_episode=params.train_n_episode, json_read=json_file_read, **train_few_shot_params)\n",
    "train_loader = train_datamgr.get_data_loader(base_file, aug=True)\n",
    "\n",
    "#------------ val data ------------------------\n",
    "test_few_shot_params = dict(n_way=params.val_n_way, n_support=params.n_shot)\n",
    "val_datamgr = SetDataManager(params.data_path, params.image_size, n_query=params.n_query, n_episode=params.val_n_episode, json_read=json_file_read, **test_few_shot_params)\n",
    "val_loader = val_datamgr.get_data_loader(val_file, aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========start testing on train set===============\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------- 导入模型 -------------------------\n",
    "model = mae_vit_base_patch16()\n",
    "state_dict = torch.load('/home/jiangweihao/code/MAE_fsl/mae_pretrain_vit_base.pth')\n",
    "state_dict = state_dict['model']\n",
    "model.load_state_dict(state_dict,strict=False)  # \n",
    "model.cuda()\n",
    "\n",
    "# from torchinfo import summary\n",
    "# summary(model,[5,3,224,224])\n",
    "\n",
    "# del model.fc                         # 删除最后的全连接层\n",
    "model.eval()\n",
    "\n",
    "def cache_model(support,query,model,mask_ratio=[0, 0.25, 0.5, 0.75],modal='mean'):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Data augmentation for the cache model\n",
    "        for i, mask in enumerate(mask_ratio):\n",
    "            \n",
    "            support_f_m, _, _ = model.forward_encoder(support,mask_ratio=mask)\n",
    "            query_f_m, _, _ = model.forward_encoder(query,mask_ratio=mask)\n",
    "            support_cls_token_m = support_f_m[:,0,:]                # 把cls_token分离出来\n",
    "            query_cls_token_m = query_f_m[:,0,:]\n",
    "            if modal == 'mean':\n",
    "                support_f_m = support_f_m[:,1:,:].mean(dim=1,keepdim=True)\n",
    "                query_f_m = query_f_m[:,1:,:].mean(dim=1,keepdim=True)\n",
    "            else:\n",
    "                support_f_m = support_f_m[:,1:,:]\n",
    "                query_f_m = query_f_m[:,1:,:]\n",
    "            if i==0:\n",
    "                support_f = support_f_m \n",
    "                query_f = query_f_m \n",
    "                support_cls_token = support_cls_token_m\n",
    "                query_cls_token = query_cls_token_m\n",
    "            else:\n",
    "                support_f = torch.cat((support_f,support_f_m),1)\n",
    "                query_f = torch.cat((query_f,query_f_m),1) \n",
    "                support_cls_token = torch.cat((support_cls_token,support_cls_token_m),1)\n",
    "                query_cls_token = torch.cat((query_cls_token,query_cls_token_m),1) \n",
    "\n",
    "    if modal == 'mean':\n",
    "        support_f = support_f.mean(dim=1).squeeze(1)   \n",
    "        query_f = query_f.mean(dim=1).squeeze(1) \n",
    "\n",
    "\n",
    "    # support_cls_token = support_cls_token.mean(dim=1)  \n",
    "    # query_cls_token = query_cls_token.mean(dim=1) \n",
    "\n",
    "    # 归一化\n",
    "    # support_f_m = support_f.mean(dim=-1, keepdim=True)\n",
    "    # support_f = support_f - support_f_m\n",
    "    support_f /= support_f.norm(dim=-1, keepdim=True)\n",
    "    support_cls_token /= support_cls_token.norm(dim=-1, keepdim=True)\n",
    "    # query_f_m = query_f.mean(dim=-1, keepdim=True)\n",
    "    # query_f = query_f - query_f_m\n",
    "    query_f /= query_f.norm(dim=-1, keepdim=True)\n",
    "    query_cls_token /= query_cls_token.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return support_f, support_cls_token, query_f, query_cls_token\n",
    "\n",
    "def catch_feature(query, model, mask_ratio=0):\n",
    "\n",
    "    with torch.no_grad():    \n",
    "\n",
    "        feature, _, _ = model.forward_encoder(query,mask_ratio=mask_ratio)\n",
    "\n",
    "    return feature[:,0,:],feature[:,1:,:]\n",
    "\n",
    "# ---------------------------------------------\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "log('==========start testing on train set===============')\n",
    "\n",
    "# for epoch in range(epochs):   \n",
    "    \n",
    "out_avg_loss = []\n",
    "timer = Timer()\n",
    "                \n",
    "avg_loss = 0\n",
    "total_correct = 0\n",
    "val_acc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idy, (temp2,target) in enumerate(train_loader):   \n",
    "temp2, target =next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拆分support,query\n",
    "support,query = temp2.split([params.n_shot,params.n_query],dim=1)\n",
    "cache_values, q_values = target.split([params.n_shot,params.n_query],dim=1)\n",
    "\n",
    "# cache_values = F.one_hot(cache_values).half()\n",
    "cache_values = cache_values.reshape(-1,cache_values.shape[-1])[:,0]\n",
    "q_values = q_values.reshape(-1)\n",
    "cache_values, q_values = cache_values.cuda(), q_values.cuda()\n",
    "\n",
    "n,k,c,h,w = support.shape\n",
    "support = support.reshape(-1,c,h,w)\n",
    "support = support.cuda()\n",
    "query = query.reshape(-1,c,h,w)\n",
    "query = query.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 224, 224])\n",
      "torch.Size([75, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(support.shape)\n",
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def patchify(imgs, patch_size=16):\n",
    "        \"\"\"\n",
    "        imgs: (N, 3, H, W)\n",
    "        x: (N, L, patch_size**2 *3)\n",
    "        \"\"\"\n",
    "        p = patch_size\n",
    "        assert imgs.shape[2] == imgs.shape[3] and imgs.shape[2] % p == 0\n",
    "\n",
    "        h = w = imgs.shape[2] // p\n",
    "        x = imgs.reshape(shape=(imgs.shape[0], 3, h, p, w, p))\n",
    "        x = torch.einsum('nchpwq->nhwpqc', x)\n",
    "        x = x.reshape(shape=(imgs.shape[0], h * w, p**2 * 3))\n",
    "        return x\n",
    "\n",
    "def unpatchify(x, patch_size=16):\n",
    "    \"\"\"\n",
    "    x: (N, L, patch_size**2 *3)\n",
    "    imgs: (N, 3, H, W)\n",
    "    \"\"\"\n",
    "    p = patch_size\n",
    "    h = w = int(x.shape[1]**.5)\n",
    "    assert h * w == x.shape[1]\n",
    "    \n",
    "    x = x.reshape(shape=(x.shape[0], h, w, p, p, 3))\n",
    "    x = torch.einsum('nhwpqc->nchpwq', x)\n",
    "    imgs = x.reshape(shape=(x.shape[0], 3, h * p, h * p))\n",
    "    return imgs\n",
    "\n",
    "def random_masking(x, mask_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Perform per-sample random masking by per-sample shuffling.\n",
    "    Per-sample shuffling is done by argsort random noise.\n",
    "    x: [N, L, D], sequence\n",
    "    \"\"\"\n",
    "    N, L, D = x.shape  # batch, length, dim\n",
    "    len_keep = int(L * (1 - mask_ratio))\n",
    "    \n",
    "    noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "    \n",
    "    # sort noise for each sample\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "    # keep the first subset\n",
    "    ids_keep = ids_shuffle[:, :len_keep]\n",
    "    x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "    # ids_keep = ids_shuffle[:, len_keep:L]\n",
    "    # y_masked = torch.gather(y, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "    # generate the binary mask: 0 is keep, 1 is remove\n",
    "    mask = torch.ones([N, L], device=x.device)\n",
    "    mask[:, :len_keep] = 0\n",
    "    # unshuffle to get the binary mask\n",
    "    mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "\n",
    "    return x_masked, mask, ids_restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 37,  3, 42, 53], device='cuda:0')\n",
      "torch.Size([75, 5])\n"
     ]
    }
   ],
   "source": [
    "print(cache_values)\n",
    "print(q_values.unsqueeze(1).repeat(1,5).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1],\n",
      "        [0, 0, 0, 0, 1]], device='cuda:0', dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "label = torch.eq(q_values.unsqueeze(1).repeat(1,5),cache_values.unsqueeze(0).repeat(75,1)).type(torch.int16)\n",
    "print(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 98, 768])\n",
      "torch.Size([5, 98, 768])\n",
      "torch.Size([75, 5, 196, 768])\n",
      "torch.Size([375, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# 将 query 和 support的图片进行交叉融合\n",
    "#--------方法1：将各自取50%，然后直接拼接-----------\n",
    "query_patch = patchify(query)          # torch.Size([75, 196, 768])\n",
    "support_patch = patchify(support)  \n",
    "query_patch, _, _ = random_masking(query_patch)         # torch.Size([75, 98, 768])\n",
    "support_patch, _, _ = random_masking(support_patch)\n",
    "print(query_patch.shape)\n",
    "print(support_patch.shape)\n",
    "imags = torch.cat((query_patch.unsqueeze(1).repeat(1,5,1,1), support_patch.unsqueeze(0).repeat(75,1,1,1)), dim=2)\n",
    "print(imags.shape)\n",
    "imags = imags.reshape(-1,imags.shape[2],imags.shape[3])\n",
    "imags = unpatchify(imags)\n",
    "print(imags.shape)\n",
    "label = label.reshape(-1)\n",
    "\n",
    "# -------方法2：将对应mask的位置互补----------------\n",
    "# 生成mask， imags = query*mask + support*(1-mask)\n",
    "def random_compose(x, y, mask_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Perform per-sample random masking by per-sample shuffling.\n",
    "    Per-sample shuffling is done by argsort random noise.\n",
    "    x: [N, L, D], sequence, query\n",
    "    y: [N, L, D], sequence, support\n",
    "    \"\"\"\n",
    "    N, L, D = x.shape  # batch, length, dim\n",
    "    N1 = y.shape[0]  # batch, length, dim\n",
    "    len_keep = int(L * (1 - mask_ratio))\n",
    "    \n",
    "    noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "    \n",
    "    # sort noise for each sample\n",
    "    ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "    ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "    # keep the first subset\n",
    "    # ids_keep = ids_shuffle[:, :len_keep]\n",
    "    # x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "    # ids_keep = ids_shuffle[:, len_keep:L]\n",
    "    # y_masked = torch.gather(y, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "    # generate the binary mask: 0 is keep, 1 is remove\n",
    "    mask = torch.ones([N, L], device=x.device)\n",
    "    one = mask\n",
    "    mask[:, :len_keep] = 0\n",
    "    # unshuffle to get the binary mask\n",
    "    mask = torch.gather(mask, dim=1, index=ids_restore)\n",
    "    mask = mask.unsqueeze(1).repeat(1,N1,1).unsqueeze(-1).repeat(1,1,1,D)\n",
    "    one = one.unsqueeze(1).repeat(1,N1,1).unsqueeze(-1).repeat(1,1,1,D)\n",
    "    x = x.unsqueeze(1).repeat(1,N1,1,1)\n",
    "    y = y.unsqueeze(0).repeat(N,1,1,1)\n",
    "    x = x * mask\n",
    "    y = y * (1-mask)\n",
    "   \n",
    "    x = x + y\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_patch = patchify(query)          # torch.Size([75, 196, 768])\n",
    "support_patch = patchify(support)\n",
    "images = random_compose(query_patch,support_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([75, 5, 196, 768])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = patchify(query)\n",
    "mask_ratio = 0.5\n",
    "N, L, D = x.shape  # batch, length, dim\n",
    "len_keep = int(L * (1 - mask_ratio))\n",
    "\n",
    "noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "\n",
    "# sort noise for each sample\n",
    "ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "ids_restore = torch.argsort(ids_shuffle, dim=1)\n",
    "\n",
    "# keep the first subset\n",
    "ids_keep = ids_shuffle[:, :len_keep]\n",
    "x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "# ids_keep = ids_shuffle[:, len_keep:L]\n",
    "# y_masked = torch.gather(y, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "\n",
    "# generate the binary mask: 0 is keep, 1 is remove\n",
    "mask = torch.ones([N, L], device=x.device)\n",
    "mask[:, :len_keep] = 0\n",
    "# unshuffle to get the binary mask\n",
    "mask = torch.gather(mask, dim=1, index=ids_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 5, 196, 768])\n",
      "torch.Size([75, 5, 196, 768])\n"
     ]
    }
   ],
   "source": [
    "mask = mask.unsqueeze(1).repeat(1,5,1).unsqueeze(-1).repeat(1,1,1,D)\n",
    "print(mask.shape)\n",
    "query_patch = patchify(query)          # torch.Size([75, 196, 768])\n",
    "support_patch = patchify(support)\n",
    "x = query_patch.unsqueeze(1).repeat(1,5,1,1)\n",
    "y = support_patch.unsqueeze(0).repeat(75,1,1,1)\n",
    "x = x * mask\n",
    "y = y * mask\n",
    "print(x.shape)\n",
    "imags = x + y\n",
    "# imags = torch.cat((query_patch.unsqueeze(1).repeat(1,5,1,1), support_patch.unsqueeze(0).repeat(75,1,1,1)), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75, 98, 768])\n",
      "torch.Size([75, 196])\n",
      "torch.Size([75, 196])\n"
     ]
    }
   ],
   "source": [
    "query_patch = patchify(query)\n",
    "# print(query_patch.shape)\n",
    "# query_recover = unpatchify(query_patch)\n",
    "# print(query_recover.shape)\n",
    "# print(query == query_recover)\n",
    "x, mask, ids_restore = random_masking(query_patch)\n",
    "print(x.shape)\n",
    "print(mask.shape)\n",
    "print(ids_restore.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 0.], device='cuda:0')\n",
      "tensor([173,   5, 175, 109, 147, 176,  67,   8, 130,   3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(mask[0][0:10])\n",
    "print(ids_restore[0][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------feature extractor------------------\n",
    "mask_ratio=[0,0.25,0.5,0.75]       # 0,0.25,0.5,0.75\n",
    "support_f , support_cls_token, query_f, query_cls_token = cache_model(support,query,model,mask_ratio=mask_ratio,modal='else')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"support_f.shape:\",support_f.shape)\n",
    "print(\"support_cls_token.shape:\",support_cls_token.shape)\n",
    "print(\"query_f.shape:\",query_f.shape)\n",
    "print(\"query_cls_token.shape:\",query_cls_token.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = (np.array([1.0,1.0,1.0,1.0])-np.array(mask_ratio))*196\n",
    "len_list = len_list.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_f_1 = support_f[:,0:int(len_list[0]),:]\n",
    "support_f_2 = support_f[:,int(len_list[0]):int(len_list[1]),:]\n",
    "support_f_3 = support_f[:,int(len_list[1]):int(len_list[2]),:]\n",
    "support_f_4 = support_f[:,int(len_list[2]):int(len_list[3]),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = int(support_cls_token.shape[1]/4)\n",
    "support_cls_token_1 = support_cls_token[:,0:l]\n",
    "support_cls_token_2 = support_cls_token[:,l:2*l]\n",
    "support_cls_token_3 = support_cls_token[:,2*l:3*l]\n",
    "support_cls_token_4 = support_cls_token[:,3*l:]\n",
    "support_cls_token_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_f_1 = query_f[:,0:int(len_list[0]),:]\n",
    "query_f_2 = query_f[:,int(len_list[0]):int(len_list[1]),:]\n",
    "query_f_3 = query_f[:,int(len_list[1]):int(len_list[2]),:]\n",
    "query_f_4 = query_f[:,int(len_list[2]):int(len_list[3]),:]\n",
    "query_f_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cls_token_1 = query_cls_token[:,0:l]\n",
    "query_cls_token_2 = query_cls_token[:,l:2*l]\n",
    "query_cls_token_3 = query_cls_token[:,2*l:3*l]\n",
    "query_cls_token_4 = query_cls_token[:,3*l:4*l]\n",
    "query_cls_token_4.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算不同mask 下得到的cls_token对余弦度量的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r15 = support_cls_token_1 @ support_cls_token_3.t()\n",
    "r15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 计算不同mask 下得到的query和support cls_token之间的关系\n",
    "qs_33 = query_cls_token_3 @ support_cls_token_3.t()\n",
    "qs_33.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(relation):\n",
    "    y = np.repeat(range(params.val_n_way),params.n_query)\n",
    "    y = torch.from_numpy(y)\n",
    "    y = y.cuda()\n",
    "\n",
    "\n",
    "    pred = relation.data.max(1)[1]\n",
    "    cos_acc = pred.eq(y).sum()/(params.train_n_way*params.n_query)\n",
    "    return cos_acc,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a , pred= acc(qs_33)\n",
    "print(a)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.repeat(range(params.val_n_way),params.n_query)\n",
    "y = torch.from_numpy(y)\n",
    "y = y.cuda()\n",
    "print(y==pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cls_token.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cls_token_reshape = query_cls_token.reshape(75,4,-1).unsqueeze(1).repeat(1,5,1,1)\n",
    "support_cls_token_reshape = support_cls_token.reshape(5,4,-1).unsqueeze(0).repeat(75,1,1,1)\n",
    "support_cls_token_reshape.shape\n",
    "\n",
    "qs = query_cls_token_reshape @ support_cls_token_reshape.transpose(3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qs.shape)\n",
    "qs = qs.reshape(75,5,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_sum = qs.sum(-1)\n",
    "print(qs_sum.shape)\n",
    "acc_sum,pred = acc(qs_sum)\n",
    "print(acc_sum)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_all = []\n",
    "pred_all = []\n",
    "for i in range(qs.shape[-1]):\n",
    "    a,pred = acc(qs[:,:,i])\n",
    "    acc_all.append(a)\n",
    "    pred_all.append(pred)\n",
    "acc_all = np.array(torch.tensor(acc_all,device='cpu')).reshape(4,4)\n",
    "print(acc_all)\n",
    "pred_all = [pred.tolist() for pred in pred_all]\n",
    "pred_all = torch.tensor(pred_all)\n",
    "print(pred_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算不同mask情况下patch 对分类的作用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_f_4:torch.Size([75, 49, 768])\n",
    "# support_f_4:torch.Size([5, 49, 768])\n",
    "def cal_sim_patch(qf,sf):\n",
    "    qf = qf.unsqueeze(1).repeat(1,5,1,1)\n",
    "    sf = sf.unsqueeze(0).repeat(75,1,1,1)\n",
    "    sim = qf @ sf.transpose(3,2)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cal_sim_patch(query_f,support_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim.shape)\n",
    "print(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_all = sim.sum(-1).sum(-1)\n",
    "acc_p_all,pred = acc(sim_all)\n",
    "print(acc_p_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = [int(l) for l in len_list]\n",
    "sim_1 = sim[:,:,0:len_list[0],0:len_list[0]]\n",
    "print(sim_1.shape)\n",
    "sim_2 = sim[:,:,len_list[0]:len_list[1],len_list[0]:len_list[1]]\n",
    "print(sim_2.shape)\n",
    "sim_3 = sim[:,:,len_list[1]:len_list[2],len_list[1]:len_list[2]]\n",
    "print(sim_3.shape)\n",
    "sim_4 = sim[:,:,len_list[2]:len_list[3],len_list[2]:len_list[3]]\n",
    "print(sim_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_p_1,_ = acc(sim_1.sum(-1).sum(-1))\n",
    "print(acc_p_1)\n",
    "acc_p_2,_ = acc(sim_2.sum(-1).sum(-1))\n",
    "print(acc_p_2)\n",
    "acc_p_3,_ = acc(sim_3.sum(-1).sum(-1))\n",
    "print(acc_p_3)\n",
    "acc_p_4,_ = acc(sim_4.sum(-1).sum(-1))\n",
    "print(acc_p_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_knn(sim,neighbor_k=3):\n",
    "    q,s,_,_= sim.shape\n",
    "    sim = sim.reshape(-1,sim.shape[2],sim.shape[3])\n",
    "    inner_sim = torch.zeros(sim.shape[0]).cuda()\n",
    "    for i in range(sim.shape[0]):\n",
    "        topk_value, topk_index = torch.topk(sim[i], neighbor_k, 1)\n",
    "        inner_sim[i] = torch.sum(topk_value)\n",
    "    inner_sim = inner_sim.reshape(q,s)\n",
    "    return inner_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_sim1 = sim_knn(sim_1)\n",
    "print(k_sim1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个patch前k个相似度\n",
    "acc_p,_ = acc(sim_knn(sim))\n",
    "print(acc_p)\n",
    "acc_p_1,_ = acc(sim_knn(sim_1))\n",
    "print(acc_p_1)\n",
    "acc_p_2,_ = acc(sim_knn(sim_2))\n",
    "print(acc_p_2)\n",
    "acc_p_3,_ = acc(sim_knn(sim_3))\n",
    "print(acc_p_3)\n",
    "acc_p_4,_ = acc(sim_knn(sim_4))\n",
    "print(acc_p_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单纯的依赖patch来计算相似度也不行\n",
    "### 利用cls_token和patch进行交叉"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 同一个图像，不同mask之下的cls_token均具有区分度，即自相关系数会高，互相关系数会低；单纯依赖cls_token之间的相似度分类，只能有0.4且mask=0.5;\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 验证以下：同一幅图像，各patch与cls_token之间的相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cls_patch_sim = support_cls_token_1.unsqueeze(1) @ support_f_1.transpose(2,1)\n",
    "cls_patch_sim = cls_patch_sim.squeeze(1)\n",
    "print(cls_patch_sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_k = 15\n",
    "topk_value, topk_index = torch.topk(cls_patch_sim, neighbor_k, 1)\n",
    "print(topk_value.shape)\n",
    "print(topk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = support_f_1[:,topk_index,:]\n",
    "sf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(1,9,(3,4,5))\n",
    "print(a)\n",
    "b = torch.randint(1,4,(3,2))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = a[:,b,:]\n",
    "# print(aa)\n",
    "aaa = aa[:,1,:,:].squeeze(1)\n",
    "print(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cls_patch_sim.sum(-1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 用分别来自query和support中的cls_token 与 patch 交叉关系来确定选取那些patch代表 整个image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用support的cls_token 和 query 的patch 的关系矩阵挑选 代表query的 patch组合\n",
    "def select_query_patch(cls_token,patch,neighbor_k = 3):\n",
    "    sim = patch.unsqueeze(1).repeat(1,5,1,1) @ cls_token.unsqueeze(1).unsqueeze(0).repeat(75,1,1,1).transpose(3,2)  # [75,196,768] [5,768]  --> [75,5,196,1]\n",
    "    sim = sim.squeeze(-1)                 # [75,5,196]\n",
    "    new_patch = torch.zeros(patch.shape[0],patch.shape[-1])\n",
    "    for i in range(sim.shape[0]):\n",
    "        _, topk_index = torch.topk(sim[i,:,:], neighbor_k, -1)             # [5,196]   -->    [5,neighbor_k]\n",
    "    # _, topk_index = torch.topk(sim[0,:,:], neighbor_k, -1)\n",
    "        tik = set(np.array(torch.tensor(topk_index.reshape(-1),device='cpu')))          # 求合集\n",
    "        tik = np.array(list(tik))\n",
    "        # new_patch = patch[i,tik,:]\n",
    "        new_patch[i] = patch[i,tik,:].mean(dim=0)\n",
    "    return new_patch\n",
    "# 利用query的cls_token 和 support 的patch 的关系矩阵挑选 代表support的 patch组合\n",
    "def select_support_patch(cls_token,patch,neighbor_k = 3):\n",
    "    sim = patch.unsqueeze(0).repeat(75,1,1,1) @ cls_token.unsqueeze(1).unsqueeze(1).repeat(1,5,1,1).transpose(3,2)\n",
    "    sim = sim.squeeze(-1)\n",
    "    sim = sim.permute(1,0,2)\n",
    "    new_patch = torch.zeros(patch.shape[0],patch.shape[-1])\n",
    "    for i in range(sim.shape[0]):\n",
    "        _, topk_index = torch.topk(sim[i,:,:], neighbor_k, -1)\n",
    "    # _, topk_index = torch.topk(sim[0,:,:], neighbor_k, -1)\n",
    "        tik = set(np.array(torch.tensor(topk_index.reshape(-1),device='cpu')))          # 求合集\n",
    "        tik = np.array(list(tik))\n",
    "        # new_patch = patch[:,tik,:]\n",
    "        new_patch[i] = patch[i,tik,:].mean(dim=0)\n",
    "    return new_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch = query_f_3\n",
    "cls_token = support_cls_token_1\n",
    "sim = patch.unsqueeze(1).repeat(1,5,1,1) @ cls_token.unsqueeze(1).unsqueeze(0).repeat(75,1,1,1).transpose(3,2)  # [75,196,768] [5,768]  --> [75,5,196,1]\n",
    "sim = sim.squeeze(-1)                 # [75,5,196]\n",
    "new_patch = torch.zeros(patch.shape[0],patch.shape[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patch.shape)\n",
    "print(cls_token.shape)\n",
    "print(sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_k =15\n",
    "i = 0 \n",
    "_, topk_index = torch.topk(sim[i,:,:], neighbor_k, -1)             # [5,196]   -->    [5,neighbor_k]\n",
    "# _, topk_index = torch.topk(sim[0,:,:], neighbor_k, -1)\n",
    "tik = set(np.array(torch.tensor(topk_index.reshape(-1),device='cpu')))          # 求合集\n",
    "tik = np.array(list(tik))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# new_patch = patch[i,tik,:]\n",
    "new_patch_ = patch[i,tik,:].mean(dim=0)\n",
    "new_patch_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patch = select_query_patch(support_cls_token_1,query_f_3,neighbor_k = 3)\n",
    "new_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_support_patch = select_support_patch(query_cls_token_3,support_f_3,neighbor_k = 3)\n",
    "new_support_patch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_patch = new_patch @ new_support_patch.t()\n",
    "sim_patch = sim_patch.cuda()\n",
    "acc_patch , pred= acc(sim_patch)\n",
    "print(acc_patch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用各自的cls_token 和 patch的关系，确定比较重要的patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_patch(cls_token,patch,neighbor_k = 15):\n",
    "    new_patch = torch.zeros(patch.shape[0],neighbor_k,patch.shape[2])\n",
    "    sim = patch @ cls_token.unsqueeze(1).transpose(2,1)          # [5,196,768] @ [5,1,768].t --> [5,196,1]\n",
    "    sim = sim.squeeze(-1)\n",
    "    \n",
    "    _, topk_index = torch.topk(sim, neighbor_k, -1)\n",
    "    new_patch = patch[:,topk_index,:][:,1,:,:].squeeze(1)\n",
    "    # new_patch = new_patch.mean(dim=1)\n",
    "    return new_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(support_f_1.shape)\n",
    "print(support_cls_token_1.unsqueeze(1).transpose(2,1).shape)\n",
    "cc = torch.bmm(support_f_1,support_cls_token_1.unsqueeze(1).transpose(2,1))\n",
    "print(cc.shape)\n",
    "_, topk_index = torch.topk(cc.squeeze(-1), neighbor_k, -1)\n",
    "new_patch = support_f_1[:,topk_index,:][:,1,:,:].squeeze(1)\n",
    "print(new_patch.shape)\n",
    "new_patch = new_patch.mean(dim=1)\n",
    "print(new_patch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spf = select_patch(support_cls_token_1,support_f_1)\n",
    "print(spf.shape)\n",
    "qyf = select_patch(query_cls_token_1,query_f_1)\n",
    "print(qyf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_qs = cal_sim_patch(qyf,spf)\n",
    "sim_select_patch = sim_knn(sim_qs)\n",
    "accu,pred = acc(sim_select_patch)\n",
    "print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select patch 加上 cls_token\n",
    "sim_qs = (qyf.mean(dim=1)+query_cls_token_3)@(spf.mean(dim=1)+support_cls_token_3).t()\n",
    "\n",
    "accu,pred = acc(sim_qs)\n",
    "print(accu)\n",
    "\n",
    "sim_qs = (query_cls_token_3)@(support_cls_token_3).t()\n",
    "\n",
    "accu,pred = acc(sim_qs)\n",
    "print(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------- test for AverageMeter  ------------------\n",
    "class AverageMeter(object):\n",
    "\t\"\"\"Computes and stores the average and current value\"\"\"\n",
    "\tdef __init__(self):\n",
    "\t\tself.reset()\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.val = 0\n",
    "\t\tself.avg = 0\n",
    "\t\tself.sum = 0\n",
    "\t\tself.count = 0\n",
    "\n",
    "\tdef update(self, val, n=1):\n",
    "\t\tself.val = val\n",
    "\t\tself.sum += val * n\n",
    "\t\tself.count += n\n",
    "\t\tself.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5.0\n",
      "4\n",
      "4.5\n"
     ]
    }
   ],
   "source": [
    "losses = AverageMeter()\n",
    "losses.update(5,3)\n",
    "print(losses.val)\n",
    "print(losses.avg)\n",
    "\n",
    "losses.update(4,3)\n",
    "print(losses.val)\n",
    "print(losses.avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwhenvtc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
